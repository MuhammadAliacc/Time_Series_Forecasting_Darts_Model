{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "from workalendar.europe import Germany\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import pvlib\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = 'E:\\TH-Koeln University\\Semester 3\\Hyperparameter tuning\\Dataset\\pv_1.csv'\n",
    "\n",
    "df = pd.read_csv(input_directory, index_col='timestampUtc', parse_dates=True)\n",
    "df.index = df.index.strftime('%Y-%m-%d %H:%M')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = df.copy()\n",
    "\n",
    "for i in range(2):\n",
    "    \n",
    "    missing_values = dataset['value'].isnull()\n",
    "    \n",
    "    for missing_index in dataset.index[missing_values]:\n",
    "        missing_timestamp = missing_index\n",
    "\n",
    "        data_2022_date = df.loc[missing_index]\n",
    "\n",
    "        year = missing_timestamp.year\n",
    "        month = missing_timestamp.month\n",
    "        day = missing_timestamp.day\n",
    "        hour = missing_timestamp.hour\n",
    "        minute = missing_timestamp.minute    \n",
    "\n",
    "        if year < 2023:\n",
    "            year += 1\n",
    "        elif year >= 2023:\n",
    "            year -= 1\n",
    "\n",
    "        adjusted_timestamp = pd.Timestamp(year, month, day, hour, minute)\n",
    "            \n",
    "        if adjusted_timestamp in dataset.index:\n",
    "            adjusted_value = dataset.loc[adjusted_timestamp, 'value']\n",
    "            dataset.loc[missing_index, 'value'] = adjusted_value\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "dataset['value'].ffill(inplace=True)\n",
    "dataset['value'].plot(figsize=(10, 6), title='Value Over Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['group_column'] = 'group_pv_1'   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = 'E:\\TH-Koeln University\\Semester 3\\Hyperparameter tuning\\Dataset\\pv_2.csv'\n",
    "\n",
    "df2 = pd.read_csv(input_directory, index_col='timestampUtc', parse_dates=True)\n",
    "df2.index = df2.index.strftime('%Y-%m-%d %H:%M')\n",
    "df2.index = pd.to_datetime(df2.index)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset2 = df2.copy()\n",
    "\n",
    "for i in range(2):\n",
    "    \n",
    "    missing_values = dataset2['value'].isnull()\n",
    "    \n",
    "    for missing_index in dataset2.index[missing_values]:\n",
    "        missing_timestamp = missing_index\n",
    "\n",
    "        data_2022_date = df.loc[missing_index]\n",
    "\n",
    "        year = missing_timestamp.year\n",
    "        month = missing_timestamp.month\n",
    "        day = missing_timestamp.day\n",
    "        hour = missing_timestamp.hour\n",
    "        minute = missing_timestamp.minute    \n",
    "\n",
    "        if year < 2023:\n",
    "            year += 1\n",
    "        elif year >= 2023:\n",
    "            year -= 1\n",
    "\n",
    "        adjusted_timestamp = pd.Timestamp(year, month, day, hour, minute)\n",
    "            \n",
    "        if adjusted_timestamp in dataset2.index:\n",
    "            adjusted_value = dataset2.loc[adjusted_timestamp, 'value']\n",
    "            dataset2.loc[missing_index, 'value'] = adjusted_value\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "dataset2['value'].ffill(inplace=True)\n",
    "dataset2['value'].plot(figsize=(10, 6), title='Value Over Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2['group_column'] = 'group_pv_2'   \n",
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model \n",
    "https://www.youtube.com/watch?v=9QtL7m3YS9I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://unit8.com/resources/time-series-forecasting-using-past-and-future-external-data-with-darts/\n",
    "\n",
    "\n",
    "helpful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://unit8co.github.io/darts/examples/01-multi-time-series-and-covariates.html\n",
    "\n",
    "from dartz website: training a global model with multiple covariates (variables or features)\n",
    "\n",
    "Darts contains many forecasting models, but not all of them can be trained on several time series. The models that support training on multiple series are called global models. An exhaustive list of the global models can be found here (bottom of the table) with for example:\n",
    "\n",
    "LinearRegressionModel\n",
    "\n",
    "BlockRNNModel\n",
    "\n",
    "Temporal Convolutional Networks (TCNModel)\n",
    "\n",
    "N-Beats (NBEATSModel)\n",
    "\n",
    "TiDEModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries, concatenate\n",
    "from darts.utils.callbacks import TFMProgressBar\n",
    "from darts.utils.timeseries_generation import (\n",
    "    gaussian_timeseries,\n",
    "    linear_timeseries,\n",
    "    sine_timeseries,\n",
    ")\n",
    "from darts.models import (\n",
    "    RNNModel,\n",
    "    TCNModel,\n",
    "    TransformerModel,\n",
    "    NBEATSModel,\n",
    "    BlockRNNModel,\n",
    "    VARIMA,\n",
    ")\n",
    "from darts.metrics import mape, smape, mae\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.datasets import AirPassengersDataset, MonthlyMilkDataset, ElectricityDataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from darts import TimeSeries\n",
    "from darts.models import ExponentialSmoothing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "def generate_torch_kwargs():\n",
    "    # run torch models on CPU, and disable progress bars for all model stages except training.\n",
    "    return {\n",
    "        \"pl_trainer_kwargs\": {\n",
    "            \"accelerator\": \"cpu\",\n",
    "            \"callbacks\": [TFMProgressBar(enable_train_bar_only=True)],\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy() \n",
    "df.reset_index(inplace=True)\n",
    "df.head()\n",
    "\n",
    "df2 = dataset2.copy() \n",
    "df2.reset_index(inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Prepare Time Series Data\n",
    "target_column = 'value'  # Replace with the actual column name\n",
    "series1 = TimeSeries.from_dataframe(df, time_col='timestampUtc', value_cols=target_column)\n",
    "\n",
    "series1 = series1[-500:]\n",
    "series1_future = series1[:-500]\n",
    "\n",
    "covariate_columns = ['t_2mc', 'aswdifd_s', 'aswdir_s', 'vmax_10m', 'tot_prec' ]  # Replace with actual column names\n",
    "covariate_series_1 = TimeSeries.from_dataframe(df, time_col='timestampUtc', value_cols=covariate_columns)\n",
    "\n",
    "covariate_series_1 = series1[-500:]\n",
    "covariate_series_1_future = series1[:-500]\n",
    "\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_target_series_1, val_target_series_1 = series1[:train_size], series1[train_size:]\n",
    "train_covariates_series_1, val_covariates_series_1 = covariate_series_1[:train_size], covariate_series_1[train_size:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Prepare Time Series Data\n",
    "target_column = 'value'  # Replace with the actual column name\n",
    "series2 = TimeSeries.from_dataframe(df2, time_col='timestampUtc', value_cols=target_column)\n",
    "\n",
    "series2 = series2[-500:]\n",
    "series2_future = series2[:-500]\n",
    "\n",
    "covariate_columns = ['t_2mc', 'aswdifd_s', 'aswdir_s', 'vmax_10m', 'tot_prec' ]  # Replace with actual column names\n",
    "covariate_series_2 = TimeSeries.from_dataframe(df2, time_col='timestampUtc', value_cols=covariate_columns)\n",
    "\n",
    "covariate_series_2 = series1[-500:]\n",
    "covariate_series_2_future = series1[:-500]\n",
    "\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "train_size = int(len(df2) * 0.8)\n",
    "train_target_series_2, val_target_series_2 = series2[:train_size], series2[train_size:]\n",
    "train_covariates_series_2, val_covariates_series_2 = covariate_series_1[:train_size], covariate_series_2[train_size:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 days 4*24*2=192\n",
    "model_name = \"BlockRNN_test\"\n",
    "model_pastcov = BlockRNNModel(\n",
    "    model=\"LSTM\",\n",
    "    input_chunk_length=500,\n",
    "    output_chunk_length=200,\n",
    "    n_epochs=3,\n",
    "    random_state=0,\n",
    "    model_name=model_name,\n",
    "    save_checkpoints=True,  # store model states: latest and best performing of validation set\n",
    "    force_reset=True,\n",
    "    **generate_torch_kwargs()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pastcov.fit(\n",
    "    series=[train_target_series_1],\n",
    "    past_covariates=[train_covariates_series_1],\n",
    "    val_series=[val_target_series_1],\n",
    "    val_past_covariates=[val_covariates_series_1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pastcov = BlockRNNModel.load_from_checkpoint(model_name=model_name, best=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a chunk of covariate_series_1 for a specific prediction period\n",
    "start_time_prediction = series1.end_time() - pd.Timedelta(days=50)  # Adjust the number of days as needed\n",
    "selected_covariates_chunk = covariate_series_1.slice(start_time_prediction, series1.end_time())\n",
    "\n",
    "# Now use selected_covariates_chunk as past covariates in the prediction\n",
    "#pred_cov = model_pastcov.predict(n=36, series=series1, past_covariates=selected_covariates_chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cov = model_pastcov.predict(n=200, series=series1, past_covariates=covariate_series_1_future)\n",
    "\n",
    "series1[-100:].plot(label=\"actual\")\n",
    "pred_cov[-100:].plot(label=\"forecast\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained with past covariates and predicting with future covatiates\n",
    "pred_cov = model_futcov.predict(n=200, series=series1, future_covariates=covariate_series_1)\n",
    "\n",
    "series1[-100:].plot(label=\"actual\")\n",
    "pred_cov[-100:].plot(label=\"forecast\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ End ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Something about multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df)\n",
    "series_multi = TimeSeries.from_group_dataframe(\n",
    "    combined_df,\n",
    "    time_col=\"timestampUtc\",\n",
    "    group_cols=\"group_column\",  # individual time series are extracted by grouping `df` by `group_cols`\n",
    "    value_cols=None,  # optionally, specify the time varying columns\n",
    "    fill_missing_dates=True,\n",
    "    freq='15min'\n",
    ")\n",
    "\n",
    "print(f\"\\n{len(series_multi)} series were extracted from the input DataFrame\")\n",
    "for i, ts in enumerate(series_multi):\n",
    "    print(f\"Static covariates of series {i}\")\n",
    "    print(ts.static_covariates)\n",
    "    ts['value'].plot(label=f\"comp1_series_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enbw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
